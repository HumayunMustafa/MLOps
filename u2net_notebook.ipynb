{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "from sagemaker import get_execution_role\n",
    "from PIL import Image\n",
    "import base64\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[01/21/25 10:50:16] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials in shared credentials file: ~<span style=\"color: #e100e1; text-decoration-color: #e100e1\">/.aws/credentials</span>   <a href=\"file:///Users/msd/Desktop/MLOps/venv/lib/python3.10/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/msd/Desktop/MLOps/venv/lib/python3.10/site-packages/botocore/credentials.py#1278\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1278</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[01/21/25 10:50:16]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials in shared credentials file: ~\u001b[38;2;225;0;225m/.aws/\u001b[0m\u001b[38;2;225;0;225mcredentials\u001b[0m   \u001b]8;id=80436;file:///Users/msd/Desktop/MLOps/venv/lib/python3.10/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=753108;file:///Users/msd/Desktop/MLOps/venv/lib/python3.10/site-packages/botocore/credentials.py#1278\u001b\\\u001b[2m1278\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "####### Upload Background Remove Model Into S3 Bucket First########\n",
    "####### This should be done once at a time since bucket will remain there unless deleted #########\n",
    "import tarfile\n",
    "sess = boto3.client('s3')\n",
    "bucket_name = 'mybackgroundremoval'\n",
    "with tarfile.open('model.tar.gz', 'w:gz') as tar:\n",
    "    tar.add('u2net.pth')\n",
    "sess.upload_file(\n",
    "    'model.tar.gz',\n",
    "    bucket_name,\n",
    "    'u2net/model.tar.gz'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deploy_model_to_sagemaker(\n",
    "    model_data_path, \n",
    "    role = None,\n",
    "    instance_type = 'ml.t2.medium',\n",
    "    initial_instance_account = 1,\n",
    "    endpoint_name = 'custom-model-endpoint',\n",
    "    framework_version= '1.8.1',\n",
    "    py_version='py3'\n",
    "):\n",
    "    if role is None:\n",
    "        raise ValueError(\"no role applied for sagemaker\")\n",
    "\n",
    "    model = PyTorchModel(\n",
    "        model_data=model_data_path,\n",
    "        role=role,\n",
    "        framework_version=framework_version,\n",
    "        py_version=py_version,\n",
    "        entry_point=\"inference.py\",\n",
    "        source_dir = 'code'\n",
    "    )\n",
    "\n",
    "    predictor = model.deploy(\n",
    "        initial_instance_count=initial_instance_account,\n",
    "        instance_type=instance_type,\n",
    "        endpoint_name=endpoint_name\n",
    "    )\n",
    "\n",
    "    return predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_instance_script():\n",
    "    return \"\"\"\n",
    "import json\n",
    "import io\n",
    "from PIL import Image\n",
    "import base64\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "class REBNCONV(nn.Module):\n",
    "    def __init__(self,in_ch=3,out_ch=3,dirate=1):\n",
    "        super(REBNCONV,self).__init__()\n",
    "\n",
    "        self.conv_s1 = nn.Conv2d(in_ch,out_ch,3,padding=1*dirate,dilation=1*dirate)\n",
    "        self.bn_s1 = nn.BatchNorm2d(out_ch)\n",
    "        self.relu_s1 = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        hx = x\n",
    "        xout = self.relu_s1(self.bn_s1(self.conv_s1(hx)))\n",
    "\n",
    "        return xout\n",
    "\n",
    "## upsample tensor 'src' to have the same spatial size with tensor 'tar'\n",
    "def _upsample_like(src,tar):\n",
    "\n",
    "    src = F.upsample(src,size=tar.shape[2:],mode='bilinear')\n",
    "\n",
    "    return src\n",
    "\n",
    "\n",
    "### RSU-7 ###\n",
    "class RSU7(nn.Module):#UNet07DRES(nn.Module):\n",
    "\n",
    "    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):\n",
    "        super(RSU7,self).__init__()\n",
    "\n",
    "        self.rebnconvin = REBNCONV(in_ch,out_ch,dirate=1)\n",
    "\n",
    "        self.rebnconv1 = REBNCONV(out_ch,mid_ch,dirate=1)\n",
    "        self.pool1 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
    "\n",
    "        self.rebnconv2 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
    "        self.pool2 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
    "\n",
    "        self.rebnconv3 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
    "        self.pool3 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
    "\n",
    "        self.rebnconv4 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
    "        self.pool4 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
    "\n",
    "        self.rebnconv5 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
    "        self.pool5 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
    "\n",
    "        self.rebnconv6 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
    "\n",
    "        self.rebnconv7 = REBNCONV(mid_ch,mid_ch,dirate=2)\n",
    "\n",
    "        self.rebnconv6d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
    "        self.rebnconv5d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
    "        self.rebnconv4d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
    "        self.rebnconv3d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
    "        self.rebnconv2d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
    "        self.rebnconv1d = REBNCONV(mid_ch*2,out_ch,dirate=1)\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        hx = x\n",
    "        hxin = self.rebnconvin(hx)\n",
    "\n",
    "        hx1 = self.rebnconv1(hxin)\n",
    "        hx = self.pool1(hx1)\n",
    "\n",
    "        hx2 = self.rebnconv2(hx)\n",
    "        hx = self.pool2(hx2)\n",
    "\n",
    "        hx3 = self.rebnconv3(hx)\n",
    "        hx = self.pool3(hx3)\n",
    "\n",
    "        hx4 = self.rebnconv4(hx)\n",
    "        hx = self.pool4(hx4)\n",
    "\n",
    "        hx5 = self.rebnconv5(hx)\n",
    "        hx = self.pool5(hx5)\n",
    "\n",
    "        hx6 = self.rebnconv6(hx)\n",
    "\n",
    "        hx7 = self.rebnconv7(hx6)\n",
    "\n",
    "        hx6d =  self.rebnconv6d(torch.cat((hx7,hx6),1))\n",
    "        hx6dup = _upsample_like(hx6d,hx5)\n",
    "\n",
    "        hx5d =  self.rebnconv5d(torch.cat((hx6dup,hx5),1))\n",
    "        hx5dup = _upsample_like(hx5d,hx4)\n",
    "\n",
    "        hx4d = self.rebnconv4d(torch.cat((hx5dup,hx4),1))\n",
    "        hx4dup = _upsample_like(hx4d,hx3)\n",
    "\n",
    "        hx3d = self.rebnconv3d(torch.cat((hx4dup,hx3),1))\n",
    "        hx3dup = _upsample_like(hx3d,hx2)\n",
    "\n",
    "        hx2d = self.rebnconv2d(torch.cat((hx3dup,hx2),1))\n",
    "        hx2dup = _upsample_like(hx2d,hx1)\n",
    "\n",
    "        hx1d = self.rebnconv1d(torch.cat((hx2dup,hx1),1))\n",
    "\n",
    "        return hx1d + hxin\n",
    "\n",
    "### RSU-6 ###\n",
    "class RSU6(nn.Module):#UNet06DRES(nn.Module):\n",
    "\n",
    "    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):\n",
    "        super(RSU6,self).__init__()\n",
    "\n",
    "        self.rebnconvin = REBNCONV(in_ch,out_ch,dirate=1)\n",
    "\n",
    "        self.rebnconv1 = REBNCONV(out_ch,mid_ch,dirate=1)\n",
    "        self.pool1 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
    "\n",
    "        self.rebnconv2 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
    "        self.pool2 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
    "\n",
    "        self.rebnconv3 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
    "        self.pool3 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
    "\n",
    "        self.rebnconv4 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
    "        self.pool4 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
    "\n",
    "        self.rebnconv5 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
    "\n",
    "        self.rebnconv6 = REBNCONV(mid_ch,mid_ch,dirate=2)\n",
    "\n",
    "        self.rebnconv5d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
    "        self.rebnconv4d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
    "        self.rebnconv3d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
    "        self.rebnconv2d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
    "        self.rebnconv1d = REBNCONV(mid_ch*2,out_ch,dirate=1)\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        hx = x\n",
    "\n",
    "        hxin = self.rebnconvin(hx)\n",
    "\n",
    "        hx1 = self.rebnconv1(hxin)\n",
    "        hx = self.pool1(hx1)\n",
    "\n",
    "        hx2 = self.rebnconv2(hx)\n",
    "        hx = self.pool2(hx2)\n",
    "\n",
    "        hx3 = self.rebnconv3(hx)\n",
    "        hx = self.pool3(hx3)\n",
    "\n",
    "        hx4 = self.rebnconv4(hx)\n",
    "        hx = self.pool4(hx4)\n",
    "\n",
    "        hx5 = self.rebnconv5(hx)\n",
    "\n",
    "        hx6 = self.rebnconv6(hx5)\n",
    "\n",
    "\n",
    "        hx5d =  self.rebnconv5d(torch.cat((hx6,hx5),1))\n",
    "        hx5dup = _upsample_like(hx5d,hx4)\n",
    "\n",
    "        hx4d = self.rebnconv4d(torch.cat((hx5dup,hx4),1))\n",
    "        hx4dup = _upsample_like(hx4d,hx3)\n",
    "\n",
    "        hx3d = self.rebnconv3d(torch.cat((hx4dup,hx3),1))\n",
    "        hx3dup = _upsample_like(hx3d,hx2)\n",
    "\n",
    "        hx2d = self.rebnconv2d(torch.cat((hx3dup,hx2),1))\n",
    "        hx2dup = _upsample_like(hx2d,hx1)\n",
    "\n",
    "        hx1d = self.rebnconv1d(torch.cat((hx2dup,hx1),1))\n",
    "\n",
    "        return hx1d + hxin\n",
    "\n",
    "### RSU-5 ###\n",
    "class RSU5(nn.Module):#UNet05DRES(nn.Module):\n",
    "\n",
    "    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):\n",
    "        super(RSU5,self).__init__()\n",
    "\n",
    "        self.rebnconvin = REBNCONV(in_ch,out_ch,dirate=1)\n",
    "\n",
    "        self.rebnconv1 = REBNCONV(out_ch,mid_ch,dirate=1)\n",
    "        self.pool1 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
    "\n",
    "        self.rebnconv2 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
    "        self.pool2 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
    "\n",
    "        self.rebnconv3 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
    "        self.pool3 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
    "\n",
    "        self.rebnconv4 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
    "\n",
    "        self.rebnconv5 = REBNCONV(mid_ch,mid_ch,dirate=2)\n",
    "\n",
    "        self.rebnconv4d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
    "        self.rebnconv3d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
    "        self.rebnconv2d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
    "        self.rebnconv1d = REBNCONV(mid_ch*2,out_ch,dirate=1)\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        hx = x\n",
    "\n",
    "        hxin = self.rebnconvin(hx)\n",
    "\n",
    "        hx1 = self.rebnconv1(hxin)\n",
    "        hx = self.pool1(hx1)\n",
    "\n",
    "        hx2 = self.rebnconv2(hx)\n",
    "        hx = self.pool2(hx2)\n",
    "\n",
    "        hx3 = self.rebnconv3(hx)\n",
    "        hx = self.pool3(hx3)\n",
    "\n",
    "        hx4 = self.rebnconv4(hx)\n",
    "\n",
    "        hx5 = self.rebnconv5(hx4)\n",
    "\n",
    "        hx4d = self.rebnconv4d(torch.cat((hx5,hx4),1))\n",
    "        hx4dup = _upsample_like(hx4d,hx3)\n",
    "\n",
    "        hx3d = self.rebnconv3d(torch.cat((hx4dup,hx3),1))\n",
    "        hx3dup = _upsample_like(hx3d,hx2)\n",
    "\n",
    "        hx2d = self.rebnconv2d(torch.cat((hx3dup,hx2),1))\n",
    "        hx2dup = _upsample_like(hx2d,hx1)\n",
    "\n",
    "        hx1d = self.rebnconv1d(torch.cat((hx2dup,hx1),1))\n",
    "\n",
    "        return hx1d + hxin\n",
    "\n",
    "### RSU-4 ###\n",
    "class RSU4(nn.Module):#UNet04DRES(nn.Module):\n",
    "\n",
    "    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):\n",
    "        super(RSU4,self).__init__()\n",
    "\n",
    "        self.rebnconvin = REBNCONV(in_ch,out_ch,dirate=1)\n",
    "\n",
    "        self.rebnconv1 = REBNCONV(out_ch,mid_ch,dirate=1)\n",
    "        self.pool1 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
    "\n",
    "        self.rebnconv2 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
    "        self.pool2 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
    "\n",
    "        self.rebnconv3 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
    "\n",
    "        self.rebnconv4 = REBNCONV(mid_ch,mid_ch,dirate=2)\n",
    "\n",
    "        self.rebnconv3d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
    "        self.rebnconv2d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
    "        self.rebnconv1d = REBNCONV(mid_ch*2,out_ch,dirate=1)\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        hx = x\n",
    "\n",
    "        hxin = self.rebnconvin(hx)\n",
    "\n",
    "        hx1 = self.rebnconv1(hxin)\n",
    "        hx = self.pool1(hx1)\n",
    "\n",
    "        hx2 = self.rebnconv2(hx)\n",
    "        hx = self.pool2(hx2)\n",
    "\n",
    "        hx3 = self.rebnconv3(hx)\n",
    "\n",
    "        hx4 = self.rebnconv4(hx3)\n",
    "\n",
    "        hx3d = self.rebnconv3d(torch.cat((hx4,hx3),1))\n",
    "        hx3dup = _upsample_like(hx3d,hx2)\n",
    "\n",
    "        hx2d = self.rebnconv2d(torch.cat((hx3dup,hx2),1))\n",
    "        hx2dup = _upsample_like(hx2d,hx1)\n",
    "\n",
    "        hx1d = self.rebnconv1d(torch.cat((hx2dup,hx1),1))\n",
    "\n",
    "        return hx1d + hxin\n",
    "\n",
    "### RSU-4F ###\n",
    "class RSU4F(nn.Module):#UNet04FRES(nn.Module):\n",
    "\n",
    "    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):\n",
    "        super(RSU4F,self).__init__()\n",
    "\n",
    "        self.rebnconvin = REBNCONV(in_ch,out_ch,dirate=1)\n",
    "\n",
    "        self.rebnconv1 = REBNCONV(out_ch,mid_ch,dirate=1)\n",
    "        self.rebnconv2 = REBNCONV(mid_ch,mid_ch,dirate=2)\n",
    "        self.rebnconv3 = REBNCONV(mid_ch,mid_ch,dirate=4)\n",
    "\n",
    "        self.rebnconv4 = REBNCONV(mid_ch,mid_ch,dirate=8)\n",
    "\n",
    "        self.rebnconv3d = REBNCONV(mid_ch*2,mid_ch,dirate=4)\n",
    "        self.rebnconv2d = REBNCONV(mid_ch*2,mid_ch,dirate=2)\n",
    "        self.rebnconv1d = REBNCONV(mid_ch*2,out_ch,dirate=1)\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        hx = x\n",
    "\n",
    "        hxin = self.rebnconvin(hx)\n",
    "\n",
    "        hx1 = self.rebnconv1(hxin)\n",
    "        hx2 = self.rebnconv2(hx1)\n",
    "        hx3 = self.rebnconv3(hx2)\n",
    "\n",
    "        hx4 = self.rebnconv4(hx3)\n",
    "\n",
    "        hx3d = self.rebnconv3d(torch.cat((hx4,hx3),1))\n",
    "        hx2d = self.rebnconv2d(torch.cat((hx3d,hx2),1))\n",
    "        hx1d = self.rebnconv1d(torch.cat((hx2d,hx1),1))\n",
    "\n",
    "        return hx1d + hxin\n",
    "\n",
    "\n",
    "##### U^2-Net ####\n",
    "class U2NET(nn.Module):\n",
    "\n",
    "    def __init__(self,in_ch=3,out_ch=1):\n",
    "        super(U2NET,self).__init__()\n",
    "\n",
    "        self.stage1 = RSU7(in_ch,32,64)\n",
    "        self.pool12 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
    "\n",
    "        self.stage2 = RSU6(64,32,128)\n",
    "        self.pool23 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
    "\n",
    "        self.stage3 = RSU5(128,64,256)\n",
    "        self.pool34 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
    "\n",
    "        self.stage4 = RSU4(256,128,512)\n",
    "        self.pool45 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
    "\n",
    "        self.stage5 = RSU4F(512,256,512)\n",
    "        self.pool56 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
    "\n",
    "        self.stage6 = RSU4F(512,256,512)\n",
    "\n",
    "        # decoder\n",
    "        self.stage5d = RSU4F(1024,256,512)\n",
    "        self.stage4d = RSU4(1024,128,256)\n",
    "        self.stage3d = RSU5(512,64,128)\n",
    "        self.stage2d = RSU6(256,32,64)\n",
    "        self.stage1d = RSU7(128,16,64)\n",
    "\n",
    "        self.side1 = nn.Conv2d(64,out_ch,3,padding=1)\n",
    "        self.side2 = nn.Conv2d(64,out_ch,3,padding=1)\n",
    "        self.side3 = nn.Conv2d(128,out_ch,3,padding=1)\n",
    "        self.side4 = nn.Conv2d(256,out_ch,3,padding=1)\n",
    "        self.side5 = nn.Conv2d(512,out_ch,3,padding=1)\n",
    "        self.side6 = nn.Conv2d(512,out_ch,3,padding=1)\n",
    "\n",
    "        self.outconv = nn.Conv2d(6*out_ch,out_ch,1)\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        hx = x\n",
    "\n",
    "        #stage 1\n",
    "        hx1 = self.stage1(hx)\n",
    "        hx = self.pool12(hx1)\n",
    "\n",
    "        #stage 2\n",
    "        hx2 = self.stage2(hx)\n",
    "        hx = self.pool23(hx2)\n",
    "\n",
    "        #stage 3\n",
    "        hx3 = self.stage3(hx)\n",
    "        hx = self.pool34(hx3)\n",
    "\n",
    "        #stage 4\n",
    "        hx4 = self.stage4(hx)\n",
    "        hx = self.pool45(hx4)\n",
    "\n",
    "        #stage 5\n",
    "        hx5 = self.stage5(hx)\n",
    "        hx = self.pool56(hx5)\n",
    "\n",
    "        #stage 6\n",
    "        hx6 = self.stage6(hx)\n",
    "        hx6up = _upsample_like(hx6,hx5)\n",
    "\n",
    "        #-------------------- decoder --------------------\n",
    "        hx5d = self.stage5d(torch.cat((hx6up,hx5),1))\n",
    "        hx5dup = _upsample_like(hx5d,hx4)\n",
    "\n",
    "        hx4d = self.stage4d(torch.cat((hx5dup,hx4),1))\n",
    "        hx4dup = _upsample_like(hx4d,hx3)\n",
    "\n",
    "        hx3d = self.stage3d(torch.cat((hx4dup,hx3),1))\n",
    "        hx3dup = _upsample_like(hx3d,hx2)\n",
    "\n",
    "        hx2d = self.stage2d(torch.cat((hx3dup,hx2),1))\n",
    "        hx2dup = _upsample_like(hx2d,hx1)\n",
    "\n",
    "        hx1d = self.stage1d(torch.cat((hx2dup,hx1),1))\n",
    "\n",
    "\n",
    "        #side output\n",
    "        d1 = self.side1(hx1d)\n",
    "\n",
    "        d2 = self.side2(hx2d)\n",
    "        d2 = _upsample_like(d2,d1)\n",
    "\n",
    "        d3 = self.side3(hx3d)\n",
    "        d3 = _upsample_like(d3,d1)\n",
    "\n",
    "        d4 = self.side4(hx4d)\n",
    "        d4 = _upsample_like(d4,d1)\n",
    "\n",
    "        d5 = self.side5(hx5d)\n",
    "        d5 = _upsample_like(d5,d1)\n",
    "\n",
    "        d6 = self.side6(hx6)\n",
    "        d6 = _upsample_like(d6,d1)\n",
    "\n",
    "        d0 = self.outconv(torch.cat((d1,d2,d3,d4,d5,d6),1))\n",
    "\n",
    "        return F.sigmoid(d0), F.sigmoid(d1), F.sigmoid(d2), F.sigmoid(d3), F.sigmoid(d4), F.sigmoid(d5), F.sigmoid(d6)\n",
    "\n",
    "### U^2-Net small ###\n",
    "class U2NETP(nn.Module):\n",
    "\n",
    "    def __init__(self,in_ch=3,out_ch=1):\n",
    "        super(U2NETP,self).__init__()\n",
    "\n",
    "        self.stage1 = RSU7(in_ch,16,64)\n",
    "        self.pool12 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
    "\n",
    "        self.stage2 = RSU6(64,16,64)\n",
    "        self.pool23 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
    "\n",
    "        self.stage3 = RSU5(64,16,64)\n",
    "        self.pool34 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
    "\n",
    "        self.stage4 = RSU4(64,16,64)\n",
    "        self.pool45 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
    "\n",
    "        self.stage5 = RSU4F(64,16,64)\n",
    "        self.pool56 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
    "\n",
    "        self.stage6 = RSU4F(64,16,64)\n",
    "\n",
    "        # decoder\n",
    "        self.stage5d = RSU4F(128,16,64)\n",
    "        self.stage4d = RSU4(128,16,64)\n",
    "        self.stage3d = RSU5(128,16,64)\n",
    "        self.stage2d = RSU6(128,16,64)\n",
    "        self.stage1d = RSU7(128,16,64)\n",
    "\n",
    "        self.side1 = nn.Conv2d(64,out_ch,3,padding=1)\n",
    "        self.side2 = nn.Conv2d(64,out_ch,3,padding=1)\n",
    "        self.side3 = nn.Conv2d(64,out_ch,3,padding=1)\n",
    "        self.side4 = nn.Conv2d(64,out_ch,3,padding=1)\n",
    "        self.side5 = nn.Conv2d(64,out_ch,3,padding=1)\n",
    "        self.side6 = nn.Conv2d(64,out_ch,3,padding=1)\n",
    "\n",
    "        self.outconv = nn.Conv2d(6*out_ch,out_ch,1)\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        hx = x\n",
    "\n",
    "        #stage 1\n",
    "        hx1 = self.stage1(hx)\n",
    "        hx = self.pool12(hx1)\n",
    "\n",
    "        #stage 2\n",
    "        hx2 = self.stage2(hx)\n",
    "        hx = self.pool23(hx2)\n",
    "\n",
    "        #stage 3\n",
    "        hx3 = self.stage3(hx)\n",
    "        hx = self.pool34(hx3)\n",
    "\n",
    "        #stage 4\n",
    "        hx4 = self.stage4(hx)\n",
    "        hx = self.pool45(hx4)\n",
    "\n",
    "        #stage 5\n",
    "        hx5 = self.stage5(hx)\n",
    "        hx = self.pool56(hx5)\n",
    "\n",
    "        #stage 6\n",
    "        hx6 = self.stage6(hx)\n",
    "        hx6up = _upsample_like(hx6,hx5)\n",
    "\n",
    "        #decoder\n",
    "        hx5d = self.stage5d(torch.cat((hx6up,hx5),1))\n",
    "        hx5dup = _upsample_like(hx5d,hx4)\n",
    "\n",
    "        hx4d = self.stage4d(torch.cat((hx5dup,hx4),1))\n",
    "        hx4dup = _upsample_like(hx4d,hx3)\n",
    "\n",
    "        hx3d = self.stage3d(torch.cat((hx4dup,hx3),1))\n",
    "        hx3dup = _upsample_like(hx3d,hx2)\n",
    "\n",
    "        hx2d = self.stage2d(torch.cat((hx3dup,hx2),1))\n",
    "        hx2dup = _upsample_like(hx2d,hx1)\n",
    "\n",
    "        hx1d = self.stage1d(torch.cat((hx2dup,hx1),1))\n",
    "\n",
    "\n",
    "        #side output\n",
    "        d1 = self.side1(hx1d)\n",
    "\n",
    "        d2 = self.side2(hx2d)\n",
    "        d2 = _upsample_like(d2,d1)\n",
    "\n",
    "        d3 = self.side3(hx3d)\n",
    "        d3 = _upsample_like(d3,d1)\n",
    "\n",
    "        d4 = self.side4(hx4d)\n",
    "        d4 = _upsample_like(d4,d1)\n",
    "\n",
    "        d5 = self.side5(hx5d)\n",
    "        d5 = _upsample_like(d5,d1)\n",
    "\n",
    "        d6 = self.side6(hx6)\n",
    "        d6 = _upsample_like(d6,d1)\n",
    "\n",
    "        d0 = self.outconv(torch.cat((d1,d2,d3,d4,d5,d6),1))\n",
    "\n",
    "        return F.sigmoid(d0), F.sigmoid(d1), F.sigmoid(d2), F.sigmoid(d3), F.sigmoid(d4), F.sigmoid(d5), F.sigmoid(d6)\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    device = torch.device(\"cude\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = U2NET()\n",
    "    model.load_state_dict(torch.load(os.path.join(model_dir, 'u2net.pth'), map_location = device))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def input_fn(request_body, request_count_instance):\n",
    "    if request_count_instance == 'application/x-image':\n",
    "        image = Image.open(io.BytesIO(request_body))\n",
    "    elif request_count_instance == 'application/json':\n",
    "        image_data = json.loads(request_body)['image']\n",
    "        image = Image.open(io.BytesIO(base64.b64.decode(image_data)))\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported Content Type: {request_content_type}\")\n",
    "\n",
    "    if image.mode != 'RGB':\n",
    "        image = image.convert('RGB')\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "        ])\n",
    "    im = transform(image)\n",
    "    im = im.unsqueeze(0)\n",
    "    return im\n",
    "\n",
    "def predict_fn(input_data, model):\n",
    "    with torch.no_grad():\n",
    "        prediction = model(input_data)\n",
    "        return prediction\n",
    "\n",
    "def output_fn(prediction, response_content_type):\n",
    "    out_image = prediction[0].squeeze()\n",
    "    out_image = out_image.cpu().numpy()\n",
    "\n",
    "    out_image = (out_image - out_image.min()) / (out_image.max() - out_image.min())  # Normalize to [0, 1]\n",
    "    out_image = (out_image * 255).astype(np.uint8)  # Scale to [0, 255]\n",
    "\n",
    "    out_image = Image.fromarray(out_image)\n",
    "\n",
    "    # if len(out_image.shape) == 3:\n",
    "    #     out_image = out_image.permute(1,2,0)\n",
    "\n",
    "    # Convert to desired output format\n",
    "    if response_content_type == 'application/x-image':\n",
    "        buffer = io.BytesIO()\n",
    "        out_image.save(buffer, format='PNG')\n",
    "        return buffer.getvalue()\n",
    "    elif response_content_type == 'application/json':\n",
    "        buffer = io.BytesIO()\n",
    "        out_image.save(buffer, format='PNG')\n",
    "        image_data = base64.b64encode(buffer.getvalue()).decode('utf-8')\n",
    "        return json.dumps({'image': image_data})\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported content type: {response_content_type}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    os.makedirs('code', exist_ok=True)\n",
    "    with open('code/inference.py', 'w') as p:\n",
    "        p.write(create_instance_script())\n",
    "\n",
    "    predictor = deploy_model_to_sagemaker(\n",
    "        model_data_path='s3://mybackgroundremoval/u2net/model.tar.gz',\n",
    "        endpoint_name='custom-endpoint-model'\n",
    "    )    \n",
    "\n",
    "    print(\"model deployed successfully \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from botocore.config import Config\n",
    "def preprocess_image(image_path ):\n",
    "    image = Image.open(image_path).resize((320, 320))\n",
    "    return image\n",
    "\n",
    "def call_sagemaker_endpoint(image_path, endpoint_name):\n",
    "    runtime = boto3.client('sagemaker-runtime', region_name = 'us-east-1', config=Config(read_timeout=220))\n",
    "    image = preprocess_image(image_path)\n",
    "    img_buffer = io.BytesIO()\n",
    "    image.save(img_buffer, format='PNG')\n",
    "    img_bytes = img_buffer.getvalue()\n",
    "\n",
    "    response = runtime.invoke_endpoint(\n",
    "        EndpointName = endpoint_name,\n",
    "        ContentType = 'application/x-image',\n",
    "        Body = img_bytes\n",
    "    )\n",
    "\n",
    "    output = response['Body'].read()\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "if __name__ == \"__main__\":\n",
    "    # main()\n",
    "    response = call_sagemaker_endpoint(\"/Users/msd/Desktop/MLOps/zidane.png\", \"custom-endpoint-model\")\n",
    "    response_dict = json.loads(response)\n",
    "    image_data_base64 = response_dict['image']\n",
    "    image_data_bytes = base64.b64decode(image_data_base64)\n",
    "    image = Image.open(io.BytesIO(image_data_bytes))\n",
    "    image.save(\"BG_output.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training job 'RF-custom-sklearn-2025-01-20-06-41-18-040' status: Completed\n",
      "Training job 'RF-custom-sklearn-2025-01-20-06-41-18-040' has already been Completed. No need to stop.\n",
      "Training job 'RF-custom-sklearn-2025-01-19-15-07-12-029' status: Completed\n",
      "Training job 'RF-custom-sklearn-2025-01-19-15-07-12-029' has already been Completed. No need to stop.\n",
      "Training job 'RF-custom-sklearn-2025-01-19-14-57-46-394' status: Failed\n",
      "Training job 'RF-custom-sklearn-2025-01-19-14-57-46-394' has already been Failed. No need to stop.\n",
      "Training job 'RF-custom-sklearn-2025-01-19-14-53-08-746' status: Failed\n",
      "Training job 'RF-custom-sklearn-2025-01-19-14-53-08-746' has already been Failed. No need to stop.\n",
      "Training job 'RF-custom-sklearn-2025-01-19-14-27-36-797' status: Failed\n",
      "Training job 'RF-custom-sklearn-2025-01-19-14-27-36-797' has already been Failed. No need to stop.\n",
      "S3 bucket mybackgroundremoval does not exist or has already been deleted.\n",
      "Action Completed!!!\n"
     ]
    }
   ],
   "source": [
    "###### In the end delete S3 bucket and Sagemaker resources either manually or through writing code below\n",
    "from botocore.exceptions import ClientError\n",
    "# Create boto3 clients\n",
    "sagemaker_client = boto3.client('sagemaker')\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "# Function to delete all SageMaker models\n",
    "def delete_sagemaker_models():\n",
    "    models = sagemaker_client.list_models()['Models']\n",
    "    for model in models:\n",
    "        model_name = model['ModelName']\n",
    "        print(f\"Deleting SageMaker model: {model_name}\")\n",
    "        sagemaker_client.delete_model(ModelName=model_name)\n",
    "\n",
    "# Function to delete all SageMaker endpoints and configurations\n",
    "def delete_sagemaker_endpoints():\n",
    "    endpoints = sagemaker_client.list_endpoints()['Endpoints']\n",
    "    for endpoint in endpoints:\n",
    "        endpoint_name = endpoint['EndpointName']\n",
    "        print(f\"Deleting SageMaker endpoint: {endpoint_name}\")\n",
    "        sagemaker_client.delete_endpoint(EndpointName=endpoint_name)\n",
    "\n",
    "    endpoint_configs = sagemaker_client.list_endpoint_configs()['EndpointConfigs']\n",
    "    for config in endpoint_configs:\n",
    "        config_name = config['EndpointConfigName']\n",
    "        print(f\"Deleting SageMaker endpoint config: {config_name}\")\n",
    "        sagemaker_client.delete_endpoint_config(EndpointConfigName=config_name)\n",
    "\n",
    "# Function to delete all SageMaker training jobs\n",
    "def delete_sagemaker_training_jobs():\n",
    "    training_jobs = sagemaker_client.list_training_jobs()['TrainingJobSummaries']\n",
    "    for job in training_jobs:\n",
    "        job_name = job['TrainingJobName']\n",
    "        try:\n",
    "            # Get the status of the training job\n",
    "            status = sagemaker_client.describe_training_job(TrainingJobName=job_name)['TrainingJobStatus']\n",
    "            print(f\"Training job '{job_name}' status: {status}\")\n",
    "\n",
    "            # Stop the job if it's still in progress\n",
    "            if status == 'InProgress':\n",
    "                print(f\"Stopping training job: {job_name}\")\n",
    "                sagemaker_client.stop_training_job(TrainingJobName=job_name)\n",
    "            elif status in ['Completed', 'Stopped', 'Failed']:\n",
    "                print(f\"Training job '{job_name}' has already been {status}. No need to stop.\")\n",
    "        except ClientError as e:\n",
    "            print(f\"Error while processing training job '{job_name}': {e}\")\n",
    "\n",
    "\n",
    "# Function to delete all objects in S3 bucket\n",
    "def delete_s3_bucket(bucket_name):\n",
    "    try:\n",
    "        # List all objects in the S3 bucket\n",
    "        objects = s3_client.list_objects_v2(Bucket=bucket_name).get('Contents', [])\n",
    "        \n",
    "        # Delete all objects in the bucket\n",
    "        for obj in objects:\n",
    "            print(f\"Deleting object {obj['Key']} from bucket {bucket_name}\")\n",
    "            s3_client.delete_object(Bucket=bucket_name, Key=obj['Key'])\n",
    "\n",
    "        # Delete the bucket itself\n",
    "        print(f\"Deleting S3 bucket: {bucket_name}\")\n",
    "        s3_client.delete_bucket(Bucket=bucket_name)\n",
    "    except s3_client.exceptions.NoSuchBucket:\n",
    "        print(f\"S3 bucket {bucket_name} does not exist or has already been deleted.\")\n",
    "        \n",
    "# Function to list and delete all SageMaker and S3 resources\n",
    "def delete_sagemaker_and_s3_resources(s3_bucket_name):\n",
    "    # Delete SageMaker resources\n",
    "    delete_sagemaker_models()\n",
    "    delete_sagemaker_endpoints()\n",
    "    delete_sagemaker_training_jobs()\n",
    "\n",
    "    # Delete S3 bucket and its contents\n",
    "    delete_s3_bucket(s3_bucket_name)\n",
    "\n",
    "# Provide the name of the S3 bucket\n",
    "s3_bucket_name = 'your-s3-bucket-name'\n",
    "\n",
    "# Call the function to delete all SageMaker and S3 resources\n",
    "delete_sagemaker_and_s3_resources(bucket_name)\n",
    "print(\"Action Completed!!!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
